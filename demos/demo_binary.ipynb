{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlkit in c:\\ml_env\\lib\\site-packages (0.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install mlkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = load_breast_cancer()\n",
    "features = diabetes.data\n",
    "feature_names = diabetes.feature_names\n",
    "targets = diabetes.target\n",
    "target_names = diabetes.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " array([[1.799e+01, 1.038e+01, 1.228e+02, 1.001e+03, 1.184e-01, 2.776e-01,\n",
       "         3.001e-01, 1.471e-01, 2.419e-01, 7.871e-02, 1.095e+00, 9.053e-01,\n",
       "         8.589e+00, 1.534e+02, 6.399e-03, 4.904e-02, 5.373e-02, 1.587e-02,\n",
       "         3.003e-02, 6.193e-03, 2.538e+01, 1.733e+01, 1.846e+02, 2.019e+03,\n",
       "         1.622e-01, 6.656e-01, 7.119e-01, 2.654e-01, 4.601e-01, 1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, 1.326e+03, 8.474e-02, 7.864e-02,\n",
       "         8.690e-02, 7.017e-02, 1.812e-01, 5.667e-02, 5.435e-01, 7.339e-01,\n",
       "         3.398e+00, 7.408e+01, 5.225e-03, 1.308e-02, 1.860e-02, 1.340e-02,\n",
       "         1.389e-02, 3.532e-03, 2.499e+01, 2.341e+01, 1.588e+02, 1.956e+03,\n",
       "         1.238e-01, 1.866e-01, 2.416e-01, 1.860e-01, 2.750e-01, 8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, 1.203e+03, 1.096e-01, 1.599e-01,\n",
       "         1.974e-01, 1.279e-01, 2.069e-01, 5.999e-02, 7.456e-01, 7.869e-01,\n",
       "         4.585e+00, 9.403e+01, 6.150e-03, 4.006e-02, 3.832e-02, 2.058e-02,\n",
       "         2.250e-02, 4.571e-03, 2.357e+01, 2.553e+01, 1.525e+02, 1.709e+03,\n",
       "         1.444e-01, 4.245e-01, 4.504e-01, 2.430e-01, 3.613e-01, 8.758e-02]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names, features[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['malignant', 'benign'], dtype='<U9'),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names, targets[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlkit.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training the model:\n",
      "\n",
      "Iter: 0. Log Loss: 0.6931471805599453.\n",
      "Iter: 1000. Log Loss: 0.5694255752359888.\n",
      "Iter: 2000. Log Loss: 0.4929124995881498.\n",
      "Iter: 3000. Log Loss: 0.43843341837000155.\n",
      "Iter: 4000. Log Loss: 0.39805781482701136.\n",
      "Iter: 5000. Log Loss: 0.3669764747471832.\n",
      "Iter: 6000. Log Loss: 0.3422321602562008.\n",
      "Iter: 7000. Log Loss: 0.32202447032763676.\n",
      "Iter: 8000. Log Loss: 0.305207926884939.\n",
      "Iter: 9000. Log Loss: 0.29091922556423644.\n",
      "Iter: 10000. Log Loss: 0.27865175714827417.\n",
      "Iter: 11000. Log Loss: 0.2679812062599668.\n",
      "Iter: 12000. Log Loss: 0.25856588107982326.\n",
      "Iter: 13000. Log Loss: 0.2501926711136587.\n",
      "Iter: 14000. Log Loss: 0.24267767533125123.\n",
      "Iter: 15000. Log Loss: 0.23593386312576822.\n",
      "Iter: 16000. Log Loss: 0.22978783428938748.\n",
      "Iter: 17000. Log Loss: 0.22416688367230359.\n",
      "Iter: 18000. Log Loss: 0.21902559842584618.\n",
      "Iter: 19000. Log Loss: 0.21427930252050378.\n",
      "Iter: 20000. Log Loss: 0.2098784805827452.\n",
      "Iter: 21000. Log Loss: 0.20579180502156433.\n",
      "Iter: 22000. Log Loss: 0.20197553427357745.\n",
      "Iter: 23000. Log Loss: 0.19839754626580425.\n",
      "Iter: 24000. Log Loss: 0.19506317647509883.\n",
      "Iter: 25000. Log Loss: 0.19192051350551181.\n",
      "Iter: 26000. Log Loss: 0.18894815667574563.\n",
      "Iter: 27000. Log Loss: 0.1861431314247455.\n",
      "Iter: 28000. Log Loss: 0.18349212738609247.\n",
      "Iter: 29000. Log Loss: 0.18096975926998507.\n",
      "Iter: 30000. Log Loss: 0.17856712854302612.\n",
      "Iter: 31000. Log Loss: 0.1762771064866851.\n",
      "Iter: 32000. Log Loss: 0.1740952918011799.\n",
      "Iter: 33000. Log Loss: 0.17201101547391456.\n",
      "Iter: 34000. Log Loss: 0.1700206349702697.\n",
      "Iter: 35000. Log Loss: 0.16811794440195013.\n",
      "Iter: 36000. Log Loss: 0.16628504036345318.\n",
      "Iter: 37000. Log Loss: 0.16452320815029162.\n",
      "Iter: 38000. Log Loss: 0.16282941862427722.\n",
      "Iter: 39000. Log Loss: 0.16119237714804296.\n",
      "Iter: 40000. Log Loss: 0.15962123795955568.\n",
      "Iter: 41000. Log Loss: 0.15811457919133132.\n",
      "Iter: 42000. Log Loss: 0.15665851009142495.\n",
      "Iter: 43000. Log Loss: 0.15524450954916896.\n",
      "Iter: 44000. Log Loss: 0.15388224476093748.\n",
      "Iter: 45000. Log Loss: 0.15256096889375495.\n",
      "Iter: 46000. Log Loss: 0.1512787427722344.\n",
      "Iter: 47000. Log Loss: 0.1500414192285702.\n",
      "Iter: 48000. Log Loss: 0.14883460248868083.\n",
      "Iter: 49000. Log Loss: 0.14766455946971332.\n",
      "Iter: 50000. Log Loss: 0.14653321848962234.\n",
      "Iter: 51000. Log Loss: 0.14542954040517753.\n",
      "Iter: 52000. Log Loss: 0.14435983582199013.\n",
      "Iter: 53000. Log Loss: 0.14331383699759787.\n",
      "Iter: 54000. Log Loss: 0.14229604822476788.\n",
      "Iter: 55000. Log Loss: 0.14130767947499995.\n",
      "Iter: 56000. Log Loss: 0.140345846101523.\n",
      "Iter: 57000. Log Loss: 0.13940533436798827.\n",
      "Iter: 58000. Log Loss: 0.13849294958417985.\n",
      "Iter: 59000. Log Loss: 0.13760176211269018.\n",
      "Iter: 60000. Log Loss: 0.13672685632815917.\n",
      "Iter: 61000. Log Loss: 0.13587558111562123.\n",
      "Iter: 62000. Log Loss: 0.13504195818713002.\n",
      "Iter: 63000. Log Loss: 0.13422938559575792.\n",
      "Iter: 64000. Log Loss: 0.1334356216084931.\n",
      "Iter: 65000. Log Loss: 0.1326617990364436.\n",
      "Iter: 66000. Log Loss: 0.13190102458779518.\n",
      "Iter: 67000. Log Loss: 0.13116264210872372.\n",
      "Iter: 68000. Log Loss: 0.13043468738700126.\n",
      "Iter: 69000. Log Loss: 0.12972761631173207.\n",
      "Iter: 70000. Log Loss: 0.12903124726085982.\n",
      "Iter: 71000. Log Loss: 0.12834319705996866.\n",
      "Iter: 72000. Log Loss: 0.1276770581878159.\n",
      "Iter: 73000. Log Loss: 0.12702038042263578.\n",
      "Iter: 74000. Log Loss: 0.1263708297192454.\n",
      "Iter: 75000. Log Loss: 0.12573766858884255.\n",
      "Iter: 76000. Log Loss: 0.12512022125293462.\n",
      "Iter: 77000. Log Loss: 0.12451320823918832.\n",
      "Iter: 78000. Log Loss: 0.12391392071842507.\n",
      "Iter: 79000. Log Loss: 0.12332902948203167.\n",
      "Iter: 80000. Log Loss: 0.12275444309717194.\n",
      "Iter: 81000. Log Loss: 0.1221905176922491.\n",
      "Iter: 82000. Log Loss: 0.12163505992417802.\n",
      "Iter: 83000. Log Loss: 0.12108569076636.\n",
      "Iter: 84000. Log Loss: 0.12054956965464446.\n",
      "Iter: 85000. Log Loss: 0.12002100010874012.\n",
      "Iter: 86000. Log Loss: 0.11950264709073474.\n",
      "Iter: 87000. Log Loss: 0.11899181074651549.\n",
      "Iter: 88000. Log Loss: 0.11849120551619179.\n",
      "Iter: 89000. Log Loss: 0.11799946844576056.\n",
      "Iter: 90000. Log Loss: 0.11751115322393056.\n",
      "Iter: 91000. Log Loss: 0.11703404665671362.\n",
      "Iter: 92000. Log Loss: 0.11656195060183584.\n",
      "Iter: 93000. Log Loss: 0.11609901574945446.\n",
      "Iter: 94000. Log Loss: 0.11564907464068101.\n",
      "Iter: 95000. Log Loss: 0.11519822261700087.\n",
      "Iter: 96000. Log Loss: 0.11475670371696481.\n",
      "Iter: 97000. Log Loss: 0.11432121274642816.\n",
      "Iter: 98000. Log Loss: 0.11389265225558931.\n",
      "Iter: 99000. Log Loss: 0.11346706612837287.\n",
      "Iter: 100000. Log Loss: 0.11305050314422842.\n",
      "\n",
      "Done.\n",
      "\n",
      "Best weights: [-1.47217376 -1.27826006 -1.5063607  -1.53166985 -0.37909716 -0.73238482\n",
      " -1.58125875 -2.18761937 -0.13976146  1.03085525 -1.69892503  0.34248316\n",
      " -1.39154238 -1.61241464  0.41421515  0.71981718  0.33210084  0.05293741\n",
      "  0.59643734  0.64879241 -2.20013763 -1.94825408 -2.09681274 -1.97213842\n",
      " -1.13263933 -1.031359   -1.43513226 -2.61832124 -0.96644272 -0.31560624].\n",
      "Best bias: 8.635591798209056.\n",
      "\n",
      "Eval metrics on train data:\n",
      "{'accuracy': 0.9648351648139597, 'precision': 0.9536423840743827, 'recall': 0.9931034482416171, 'f1': 0.9729729682067202}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlkit.linear_model.LogisticRegression.LogisticRegression at 0x1f6bfa12a30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlkit.linear_model import LogisticRegression\n",
    "from mlkit.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "cls_model = LogisticRegression(method=\"gd\")\n",
    "cls_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.956140350793321,\n",
       " 'precision': 0.9305555554263119,\n",
       " 'recall': 0.9999999998507464,\n",
       " 'f1': 0.9640287721929507}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
